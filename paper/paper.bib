@misc{lanctot2020openspielframeworkreinforcementlearning,
      title={OpenSpiel: A Framework for Reinforcement Learning in Games}, 
      author={Marc Lanctot and Edward Lockhart and Jean-Baptiste Lespiau and Vinicius Zambaldi and Satyaki Upadhyay and Julien Pérolat and Sriram Srinivasan and Finbarr Timbers and Karl Tuyls and Shayegan Omidshafiei and Daniel Hennes and Dustin Morrill and Paul Muller and Timo Ewalds and Ryan Faulkner and János Kramár and Bart De Vylder and Brennan Saeta and James Bradbury and David Ding and Sebastian Borgeaud and Matthew Lai and Julian Schrittwieser and Thomas Anthony and Edward Hughes and Ivo Danihelka and Jonah Ryan-Davis},
      year={2020},
      eprint={1908.09453},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/1908.09453}, 
}

@inproceedings{Ng1999PolicyIU,
  title={Policy Invariance Under Reward Transformations: Theory and Application to Reward Shaping},
  author={A. Ng and Daishi Harada and Stuart J. Russell},
  booktitle={International Conference on Machine Learning},
  year={1999},
  url={https://api.semanticscholar.org/CorpusID:5730166}
}

@manual{asart_reglamento_archived,
  title        = {Reglamento Oficial de Truco Argentino},
  author       = {{Asociación Argentina de Truco}},
  organization = {ASART},
  year         = {2022},
  url          = {https://web.archive.org/web/20220102235725/https://asart.com.ar/wp-content/uploads/reglamento/reglamento-oficial-asart.pdf},
  note         = {Consultado vía Wayback Machine (Internet Archive)},
  howpublished = {Recuperado de \url{https://web.archive.org/web/20220102235725/https://asart.com.ar/wp-content/uploads/reglamento/reglamento-oficial-asart.pdf}}
}

% ==========================================
% Algoritmos de Regret Minimization
% ==========================================

@inproceedings{zinkevich2007regret,
  title     = {Regret Minimization in Games with Incomplete Information},
  author    = {Zinkevich, Martin and Johanson, Michael and Bowling, Michael and Piccione, Carmelo},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {20},
  year      = {2007},
  publisher = {Curran Associates, Inc.}
}

@inproceedings{lanctot2009monte,
  title     = {Monte Carlo Sampling for Regret Minimization in Extensive Games},
  author    = {Lanctot, Marc and Waugh, Kevin and Zinkevich, Martin and Bowling, Michael},
  booktitle = {Advances in Neural Information Processing Systems},
  volume    = {22},
  year      = {2009},
  publisher = {Curran Associates, Inc.}
}

@inproceedings{brown2019deep,
  title     = {Deep Counterfactual Regret Minimization},
  author    = {Brown, Noam and Lerer, Adam and Gross, Sam and Sandholm, Tuomas},
  booktitle = {International Conference on Machine Learning},
  pages     = {793--802},
  year      = {2019},
  organization = {PMLR}
}

% ==========================================
% Algoritmos híbridos (RL + Teoría de Juegos)
% ==========================================

@article{heinrich2016deep,
  title   = {Deep Reinforcement Learning from Self-Play in Imperfect-Information Games},
  author  = {Heinrich, Johannes and Silver, David},
  journal = {arXiv preprint arXiv:1603.01121},
  year    = {2016}
}

% ==========================================
% Algoritmos de Reinforcement Learning
% ==========================================

@article{schulman2017proximal,
  title   = {Proximal Policy Optimization Algorithms},
  author  = {Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal = {arXiv preprint arXiv:1707.06347},
  year    = {2017}
}

@article{mnih2015human,
  title     = {Human-level control through deep reinforcement learning},
  author    = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal   = {Nature},
  volume    = {518},
  number    = {7540},
  pages     = {529--533},
  year      = {2015},
  publisher = {Nature Publishing Group}
}

@book{sutton2018reinforcement,
  title     = {Reinforcement Learning: An Introduction},
  author    = {Sutton, Richard S. and Barto, Andrew G.},
  year      = {2018},
  edition   = {2},
  publisher = {MIT Press},
  address   = {Cambridge, MA}
}

% ==========================================
% Algoritmos de Búsqueda (MCTS, AlphaZero)
% ==========================================

@article{silver2018general,
  title     = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
  author    = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and others},
  journal   = {Science},
  volume    = {362},
  number    = {6419},
  pages     = {1140--1144},
  year      = {2018},
  publisher = {American Association for the Advancement of Science}
}

@inproceedings{kocsis2006bandit,
  title        = {Bandit based Monte-Carlo planning},
  author       = {Kocsis, Levente and Szepesv{\'a}ri, Csaba},
  booktitle    = {European Conference on Machine Learning},
  pages        = {282--293},
  year         = {2006},
  organization = {Springer}
}

% ==========================================
% Teoría de Juegos y Equilibrio de Nash
% ==========================================

@book{shoham2008multiagent,
  title     = {Multiagent Systems: Algorithmic, Game-Theoretic, and Logical Foundations},
  author    = {Shoham, Yoav and Leyton-Brown, Kevin},
  year      = {2008},
  publisher = {Cambridge University Press}
}

@article{nash1950equilibrium,
  title     = {Equilibrium points in n-person games},
  author    = {Nash, John F.},
  journal   = {Proceedings of the National Academy of Sciences},
  volume    = {36},
  number    = {1},
  pages     = {48--49},
  year      = {1950},
  publisher = {National Academy of Sciences}
}
